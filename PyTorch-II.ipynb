{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNeRknxAR0f7KBkczCv9OBC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**Discovering Activation Functions**"],"metadata":{"id":"XB8A_sXK2sY2"}},{"cell_type":"markdown","source":["Sigmoid aktivasyon fonksiyonu ikili sınıflandırma sonuçları için döner. Örneğin bir canlı ya memelidir ya değildir."],"metadata":{"id":"FKwrp4HZ5tYD"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"h_AbE-rd2nZl"},"outputs":[],"source":["import torch\n","import torch.nn as nn"]},{"cell_type":"code","source":["input_tensor=torch.tensor([[6]])\n","sigmoid = nn.Sigmoid()"],"metadata":{"id":"z0AXf8eb58-J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["output = sigmoid(input_tensor)"],"metadata":{"id":"voOaM78A6HTy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["output"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-hO2fQQA6HWR","executionInfo":{"status":"ok","timestamp":1753184030974,"user_tz":-180,"elapsed":87,"user":{"displayName":"Merve Arta","userId":"05970951927538737266"}},"outputId":"52f406d1-8b80-4cf4-f810-ac9f92f2630e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.9975]])"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["Sigmoid Activation As the last layer"],"metadata":{"id":"xM3PY02s6ZvL"}},{"cell_type":"code","source":["model = nn.Sequential(\n","    nn.Linear(6,4),\n","    nn.Linear(4,1),\n","    nn.Sigmoid()\n",")"],"metadata":{"id":"6pLH1Hnv6h6p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DdYBt4cy8YJs","executionInfo":{"status":"ok","timestamp":1753184577603,"user_tz":-180,"elapsed":12,"user":{"displayName":"Merve Arta","userId":"05970951927538737266"}},"outputId":"3277ad10-495b-4b1a-9845-a718512cbec3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Sequential(\n","  (0): Linear(in_features=6, out_features=4, bias=True)\n","  (1): Linear(in_features=4, out_features=1, bias=True)\n","  (2): Sigmoid()\n",")"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["Softmax Activation"],"metadata":{"id":"5RKDuOoz8iGV"}},{"cell_type":"code","source":["input_tensor = torch.tensor(\n","    [[4.3,6.1,2.3]]\n",")"],"metadata":{"id":"8xKZqrBF8pjp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["probabilities = nn.Softmax(dim=-1)\n","output_tensor = probabilities(input_tensor)"],"metadata":{"id":"76RL9-7o8ygQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["output_tensor"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hr6mWX0p8-HI","executionInfo":{"status":"ok","timestamp":1753184730312,"user_tz":-180,"elapsed":8,"user":{"displayName":"Merve Arta","userId":"05970951927538737266"}},"outputId":"0d751f69-8e55-4e17-d4cc-7e084c4d1387"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.1392, 0.8420, 0.0188]])"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["input_tensor = torch.tensor([[2.4]])\n","\n","# Create a sigmoid function and apply it on input_tensor\n","sigmoid = nn.Sigmoid()\n","output = sigmoid(input_tensor)\n","print(output)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KNvb-M6C-zsi","executionInfo":{"status":"ok","timestamp":1753185209923,"user_tz":-180,"elapsed":7,"user":{"displayName":"Merve Arta","userId":"05970951927538737266"}},"outputId":"2861e4c8-3af6-4086-9fd6-0a9c1f51e0a7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.9168]])\n"]}]},{"cell_type":"code","source":["input_tensor = torch.tensor([[1.0, -6.0, 2.5, -0.3, 1.2, 0.8]])\n","\n","# Create a softmax function and apply it on input_tensor\n","softmax = nn.Softmax()\n","probabilities = softmax(input_tensor)\n","print(probabilities)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MEQBGg7O-1UA","executionInfo":{"status":"ok","timestamp":1753185221104,"user_tz":-180,"elapsed":10,"user":{"displayName":"Merve Arta","userId":"05970951927538737266"}},"outputId":"90090a5e-1fcb-41d8-f30e-1f55246a8741"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1.2828e-01, 1.1698e-04, 5.7492e-01, 3.4961e-02, 1.5669e-01, 1.0503e-01]])\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1739: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  return self._call_impl(*args, **kwargs)\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","\n","input_tensor = torch.Tensor([[3, 4, 6, 7, 10, 12, 2, 3, 6, 8, 9]])\n","\n","# Update network below to perform a multi-class classification with four labels\n","model = nn.Sequential(\n","  nn.Linear(11, 20),\n","  nn.Linear(20, 12),\n","  nn.Linear(12, 6),\n","  nn.Linear(6, 4),\n","  nn.Softmax()\n",")\n","\n","output = model(input_tensor)\n","print(output)"],"metadata":{"id":"Jf4wcsq0-1bq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1753253021431,"user_tz":-180,"elapsed":5810,"user":{"displayName":"Merve Arta","userId":"05970951927538737266"}},"outputId":"52d54264-2f97-47de-acfd-4c8b1d24b252"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.0661, 0.5997, 0.2115, 0.1227]], grad_fn=<SoftmaxBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1739: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  return self._call_impl(*args, **kwargs)\n"]}]},{"cell_type":"markdown","source":["**One - Hat Encoding**\n","\n","Tahmin ettiğimiz y gerçek değerinin ,karşılaştırabilmek için tensör olarak dönüştürme işlemidir."],"metadata":{"id":"8N70BzCnPO13"}},{"cell_type":"code","source":["import torch.nn.functional as F"],"metadata":{"id":"_kJijTRFPnWI","executionInfo":{"status":"ok","timestamp":1753256770883,"user_tz":-180,"elapsed":17,"user":{"displayName":"Merve Arta","userId":"05970951927538737266"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["print(F.one_hot(torch.tensor(0),num_classes = 3 ))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Iq8znfjTPqE0","executionInfo":{"status":"ok","timestamp":1753256771885,"user_tz":-180,"elapsed":31,"user":{"displayName":"Merve Arta","userId":"05970951927538737266"}},"outputId":"d51454b8-de48-44b6-fe02-c7810363d738"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1, 0, 0])\n"]}]},{"cell_type":"code","source":["print(F.one_hot(torch.tensor(1),num_classes = 3 ))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5nPOYsYhP04M","executionInfo":{"status":"ok","timestamp":1753256785718,"user_tz":-180,"elapsed":38,"user":{"displayName":"Merve Arta","userId":"05970951927538737266"}},"outputId":"a383dbbe-f36e-4a09-ddba-ff750cd32104"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([0, 1, 0])\n"]}]},{"cell_type":"code","source":["print(F.one_hot(torch.tensor(2),num_classes = 3 ))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ygCz-uGAP0-v","executionInfo":{"status":"ok","timestamp":1753256787009,"user_tz":-180,"elapsed":27,"user":{"displayName":"Merve Arta","userId":"05970951927538737266"}},"outputId":"6fc9e7e4-d33f-4a63-cb9f-5ff7a7f407e6"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([0, 0, 1])\n"]}]},{"cell_type":"code","source":["from torch.nn import CrossEntropyLoss\n","\n","scores = torch.tensor([-5.2,4.6,0.8])\n","one_hat_target = torch.tensor([1,0,0])\n","\n","\n","criterion = CrossEntropyLoss()\n","print(criterion(scores.double(),one_hat_target.double()))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mjfjcFglRq4-","executionInfo":{"status":"ok","timestamp":1753257389167,"user_tz":-180,"elapsed":27,"user":{"displayName":"Merve Arta","userId":"05970951927538737266"}},"outputId":"968ecb8c-6a50-4150-8c21-d2ff63139287"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(9.8222, dtype=torch.float64)\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn.functional as F\n","from torch.nn import CrossEntropyLoss\n","\n","y = [2] #zaten array olduğu için direkt tensor içine koyalım\n","scores = torch.tensor([[0.1, 6.0, -2.0, 3.2]])\n","\n","# Create a one-hot encoded vector of the label y\n","one_hot_label = F.one_hot(torch.tensor(y), num_classes=4)\n","\n","# Create the cross entropy loss function\n","criterion = CrossEntropyLoss()\n","\n","# Calculate the cross entropy loss\n","loss = criterion(scores.double(), one_hot_label.double())\n","print(loss)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WsN7WnvKVEwe","executionInfo":{"status":"ok","timestamp":1753258205478,"user_tz":-180,"elapsed":18,"user":{"displayName":"Merve Arta","userId":"05970951927538737266"}},"outputId":"a99dbe49-7fbb-4d18-9b76-d59262000d8e"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(8.0619, dtype=torch.float64)\n"]}]},{"cell_type":"markdown","source":["**Gradients**\n","Loss Functiondan sora gradients hesaplıyoru. gradients dediğimiz şey türevdir,yani eğim yani bizim modelimiz hata değerinin ne kadar yüksek olduğunu hesaplıyoruz. buradan aldığımız değer ile birlikte model içindeki bias ve weights değerlerini güncelliyoruz çünkü model bu değerleri önceden kendisi atıyordu."],"metadata":{"id":"fX-jEmT_avlN"}},{"cell_type":"markdown","source":["model = nn.Sequential(\n","    nn.Linear(16,8),\n","    nn.Linear(8,4),\n","    nn.Linear(4,2),\n",")\n","prediction = model(sample)\n","\n","criterion = CrossEntropyLoss()\n","loss = criterion(prediction,target)\n","loss.backward()\n","\n","\n","model[0].weight.grad\n","model[0].bias.grad\n","model[1].weight.grad\n","model[1].bias.grad\n","model[2].weight.grad\n","model[2].bias.grad"],"metadata":{"id":"B4JcbG-QyOTs"}},{"cell_type":"code","source":["import torch.optim as optim\n","\n","optimizer = optim.SGD(model.parameters(),lr=0.001)\n","\n","optimizer.step()"],"metadata":{"id":"cuDBuMxpbb_j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create the optimizer\n","optimizer = optim.SGD(model.parameters(), lr=0.001)\n","\n","loss = criterion(pred, target)\n","loss.backward()\n","\n","# Update the model's parameters using the optimizer\n","optimizer.step()"],"metadata":{"id":"oBJPnczv1e8e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["weight0 = model[0].weight\n","weight1 = model[1].weight\n","weight2 = model[2].weight\n","\n","# Access the gradients of the weight of each linear layer\n","grads0 = model[0].weight.grad\n","grads1 = model[1].weight.grad\n","grads2 = model[2].weight.grad"],"metadata":{"id":"puV4htGC0xCv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["weight0 = model[0].weight\n","weight1 = model[1].weight\n","weight2 = model[2].weight\n","\n","# Access the gradients of the weight of each linear layer\n","grads0 = weight0.grad\n","grads1 = weight1.grad\n","grads2 = weight2.grad\n","\n","# Update the weights using the learning rate and the gradients\n","weight0 = weight0 - grads0*lr\n","weight1 = weight1 - grads1*lr\n","weight2 = weight2 - grads2*lr"],"metadata":{"id":"VLM_2agK0ynS"},"execution_count":null,"outputs":[]}]}